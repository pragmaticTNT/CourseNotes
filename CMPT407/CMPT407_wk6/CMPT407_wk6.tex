%
% This is a borrowed LaTeX template file for lecture notes for CS267,
% Applications of Parallel Computing, UCBerkeley EECS Department.
% Now being used for CMU's 10725 Fall 2012 Optimization course
% taught by Geoff Gordon and Ryan Tibshirani.  When preparing 
% LaTeX notes for this class, please use this template.
%
% To familiarize yourself with this template, the body contains
% some examples of its use.  Look them over.  Then you can
% run LaTeX on this file.  After you have LaTeXed this file then
% you can look over the result either by printing it out with
% dvips or using xdvi. "pdflatex template.tex" should also work.
%

\documentclass[twoside]{article}
\setlength{\oddsidemargin}{0.25 in}
\setlength{\evensidemargin}{-0.25 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{8.5 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

%
% ADD PACKAGES here:
%

\usepackage{amsmath,amsfonts,amssymb, graphicx}
\usepackage{color}
\usepackage{comment}
\usepackage{mathtools}

%
% The following commands set up the lecnum (lecture number)
% counter and make various numbering schemes work relative
% to the lecture number.
%
\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}

%
% The following macro is used to generate the header.
%
\newcommand{\lecture}[4]{
   \pagestyle{myheadings}
   \thispagestyle{plain}
   \newpage
   \setcounter{lecnum}{#1}
   \setcounter{page}{1}
   \noindent
   \begin{center}
   \framebox{
      \vbox{\vspace{2mm}
    \hbox to 6.28in { {\bf CMPT 407: Computational Complexity
	\hfill Summer 2017} }
       \vspace{4mm}
       \hbox to 6.28in { {\Large \hfill Lecture #1: #2  \hfill} }
       \vspace{2mm}
       \hbox to 6.28in { {\it Lecturer: #3 \hfill Scribe: #4} }
      \vspace{2mm}}
   }
   \end{center}
   \markboth{Lecture #1: #2}{Lecture #1: #2}

   %{\bf Note}: {\it LaTeX template courtesy of UC Berkeley EECS dept.}

   %{\bf Disclaimer}: {\it These notes have not been subjected to the
   %usual scrutiny reserved for formal publications.  They may be distributed
   %outside this class only with the permission of the Instructor.}
   \vspace*{4mm}
}
%
% Convention for citations is authors' initials followed by the year.
% For example, to cite a paper by Leighton and Maggs you would type
% \cite{LM89}, and to cite a paper by Strassen you would type \cite{S69}.
% (To avoid bibliography problems, for now we redefine the \cite command.)
% Also commands that create a suitable format for the reference list.
%\renewcommand{\citep{â€¢}ite}[1]{[#1]}
\def\beginrefs{\begin{list}%
        {[\arabic{equation}]}{\usecounter{equation}
         \setlength{\leftmargin}{2.0truecm}\setlength{\labelsep}{0.4truecm}%
         \setlength{\labelwidth}{1.6truecm}}}
\def\endrefs{\end{list}}
\def\bibentry#1{\item[\hbox{[#1]}]}

%Use this command for a figure; it puts a figure in wherever you want it.
%usage: \fig{NUMBER}{SPACE-IN-INCHES}{CAPTION}
\newcommand{\fig}[3]{
			\vspace{#2}
			\begin{center}
			Figure \thelecnum.#1:~#3
			\end{center}
	}
% Use these for theorems, lemmas, proofs, etc.
\newtheorem{theorem}{Theorem}[lecnum]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newenvironment{proof}{{\bf Proof:}}{\hfill\rule{2mm}{2mm}}

% **** IF YOU WANT TO DEFINE ADDITIONAL MACROS FOR YOURSELF, PUT THEM HERE:

\newcommand\E{\mathbb{E}}
\def\N{\mathbb{N}}
\def\R{\mathbb{R}}
\def\P{\mathsf{P}}
\def\NP{\mathsf{NP}}
\def\BPP{\mathsf{BPP}}
\def\BQP{\mathsf{BQP}}
\def\RP{\mathsf{RP}}
\def\ZPP{\mathsf{ZPP}}
\def\coRP{\mathsf{coRP}}
\def\SAT{\mathsf{SAT}}
\def\PolySize{\mathsf{PolySize}}

\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\DeclarePairedDelimiter\anglebrac{\langle}{\rangle}

\begin{document}
%\lecture{**LECTURE-NUMBER**}{**DATE**}{**LECTURER**}{**SCRIBE**}
\lecture{6}{Randomized Computation (12 - 16 June)}{Valentine Kabanets}{Lily Li}
%\footnotetext{These notes are partially based on those of Nigel Mansell.}

The complexity classes we are going to consider in the next little while:
\[\P \subseteq \BPP \subseteq \BQP\]
where $\BPP$ is randomized polynomial time algorithm (assuming access to uniform random bits) and $\BQP$ is quantum polynomial time (assuming Quantum Mechanics is accurate and we can build large quantum systems.

Consider an example in Communication Complexity. Consider two parties $Alice$ and $Bob$ with strings $a$ and $b$ respectively. They both want to know if $a = b$. Let the cost of a protocol is the number of bits sent between the two parties. Consider the following deterministic protocol: $Alice$ sends $Bob$ string $a$. $Bob$ compares $a$ and $b$ and sends $Alice$ one bit denoting if they are equal or not. The complexity of the protocol is $n + 1$ for strings of length $n$. As it turns out, the best we can do with a deterministic protocol is $n$.

What if we use a randomized protocol? $Alice$ picks a random prime number $p$ in the range $(n^2, n^3)$ and a random number $r$ in the range $(1, p)$. For $a = a_1\cdots a_n$, $Alice$ calculates $A(r) = a_1 r^{n-1} + \cdot + a_n \mod p$. $Alice$ sends $Bob$ the string $(q, r, A(r))$ (actually $p$ is not necessary but you might as well send it anyways). For $b = b_1 \cdots b_n$, $Bob$ computes $B(r) = b_1 r^{n-1} + \cdots + b_n \mod p$ and compares $A(r)$ and $B(r)$ returning $Alice$ one bit. The cost of this protocol is $9\log n$. To see how good this protocol is 
 
\section{Randomized Complexity Class}
A more granular subdivision of Randomized Complexity classes:
\[\ZPP \subset \RP \subset \BPP\]
\begin{definition}
A language $L \in \BPP$ if there is a polynomial time DTM $M(x, r)$ such that $\forall x \in L$.

Similarly the one sized randomized complexity class $\RP$ is defined as: .

Finally the class $\ZPP$ is defined as  
\end{definition}

To construct a randomized algorithm we need to ensure that

\begin{theorem}
If $L \in \RP$ (recall $\frac{1}{2}$ chance of error for accepting) then we can reduce the error to $\frac{1}{2^n}$ for any $n\in \N$.
\end{theorem}
\begin{proof}
Quite straight forward. Just run the RTM $M$ on input $x$ a bunch of times. If any trial accepts then $x \in L$ since $M$ cannot be wrong on rejecting inputs.
\end{proof}

\begin{theorem}
If $L \in \BPP$ (recall $\frac{1}{4}$ chance of error for both accepting and rejecting) then we can reduce the error to $\frac{1}{2^n}$ for any $n\in \N$.
\end{theorem}

Now lets consider $\ZPP$ in-depth:
\begin{theorem}
$L \in \ZPP \iff L \in \RP \cap \coRP \iff$ there exists a randomized algorithm that is always correct and has expected polynomial running time. With random variable $T(x, r)$ be the running time on input $x$ with randomness $r$. The expected running time on $x$ is $Exp_r[T(x,r)] = \sum_r T(x,r) \cdot Pr(r)$. 	  
\end{theorem}
\begin{proof}
First show the first $\iff$ holds. In particular we will show that $L \in \RP \cap \bar{L} \in \RP \implies L \in \ZPP$. Next we have $L \in \ZPP$ and need to show that $L \in \RP \cap \bar{L} \in \ZPP$. 

For the next we show that $L \in \ZPP \iff$ there exists and algorithm which runs in an expected polynomial time. In the backwards direction 

In the forward direction 
\end{proof}

\begin{theorem}
There exists a zero-error $\ZPP$ randomized algorithm for $k-\SAT$ in expected time $2^{n(1 - \frac{\epsilon}{k})}$ with constant $\epsilon > 0$. 
\end{theorem}
\begin{proof}
Do you still remember the switching lemma? It will come in handy.
\end{proof}

The following is an application of our discussion thus far:
\begin{theorem}
$\BPP \subseteq \PolySize$
\end{theorem}
\begin{proof}
Suppose $L \in \BPP$. Then on input $x$, the probability that $M(x,r)$ is wrong can be made quite small: $\leq 2^{-2n}$. Consider the grid with all $n$ bit string inputs $x_1, ..., x_{2^n}$ down the rows and all the random strings $r_1, ..., r_{2^{PolySize}}$ across the columns. Each cell $(i,j)$ of the table accepts or rejects depending on the value of $M(x_i, r_j)$. For each row the expected number of wrong results is $2^{-2n}$. Using union bound we have that the expected number of  
\end{proof}

It is conjectured that $\BPP = \P$ though I have no idea why this is...
\end{document}